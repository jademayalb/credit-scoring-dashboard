"""
Client API pour la page de simulation.

But : isoler la logique POST utilisée par la page de simulation afin de ne pas modifier
utils/api_client.py et ne pas impacter les autres pages.
"""
import requests
import logging
from typing import Optional, Dict, Any

from config import PREDICT_ENDPOINT, DEFAULT_THRESHOLD
# fallback vers l'ancien helper si besoin (on n'y touche pas)
try:
    from utils.api_client import get_client_prediction as fallback_get_client_prediction
except Exception:
    fallback_get_client_prediction = None

logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO)


def simulate_prediction(client_id: Optional[int] = None, features: Optional[Dict[str, Any]] = None, timeout: int = 12) -> Optional[Dict[str, Any]]:
    """
    Envoie une requête de type POST à l'API de prédiction pour simuler un profil.

    - Si l'API accepte POST, on envoie d'abord :
        POST PREDICT_ENDPOINT + <client_id> (si client_id donné) json: {"features": {...}, "client_id": ...}
      puis POST PREDICT_ENDPOINT json: {"features": {...}, "client_id": ...}
    - Si aucun POST ne répond correctement et qu'un fallback est disponible, on appelle fallback_get_client_prediction.
    - Retour formaté: {"client_id": ..., "probability": float, "threshold": float, "decision": str, "raw_data": {...}}

    Ne met PAS en cache : une simulation doit toujours prendre la réponse la plus récente.
    """
    if features is None:
        features = {}

    payload = {"features": features}
    if client_id is not None:
        try:
            payload["client_id"] = int(client_id)
        except Exception:
            payload["client_id"] = client_id

    # Tentative 1: POST vers PREDICT_ENDPOINT + client_id
    tried = []
    if client_id is not None:
        url1 = f"{PREDICT_ENDPOINT}{client_id}"
        tried.append(url1)
        try:
            resp = requests.post(url1, json=payload, timeout=timeout)
            if resp.status_code == 200:
                data = resp.json()
                return _normalize_response(data, client_id)
            else:
                logger.info(f"simulate_prediction: POST {url1} -> {resp.status_code}")
        except Exception as e:
            logger.debug(f"simulate_prediction: POST {url1} exception: {e}")

    # Tentative 2: POST vers PREDICT_ENDPOINT
    tried.append(PREDICT_ENDPOINT)
    try:
        resp = requests.post(PREDICT_ENDPOINT, json=payload, timeout=timeout)
        if resp.status_code == 200:
            data = resp.json()
            return _normalize_response(data, client_id)
        else:
            logger.info(f"simulate_prediction: POST {PREDICT_ENDPOINT} -> {resp.status_code}")
    except Exception as e:
        logger.debug(f"simulate_prediction: POST {PREDICT_ENDPOINT} exception: {e}")

    # Fallback: utiliser get_client_prediction si disponible (GET-based or existing logic)
    if fallback_get_client_prediction is not None:
        logger.info(f"simulate_prediction: aucun POST valide ({tried}), fallback vers get_client_prediction()")
        try:
            return fallback_get_client_prediction(client_id=client_id, features=features)
        except Exception as e:
            logger.exception("simulate_prediction: fallback get_client_prediction a échoué.")
            return None

    logger.warning(f"simulate_prediction: aucun endpoint POST dispo ({tried}) et pas de fallback.")
    return None


def _normalize_response(data: Dict[str, Any], client_id: Optional[int]) -> Dict[str, Any]:
    """
    Normalise la réponse de l'API pour correspondre au format attendu par l'UI.
    """
    return {
        "client_id": int(client_id) if client_id is not None else data.get("client_id", None),
        "probability": data.get("probability", data.get("prob", 0.0)),
        "threshold": data.get("threshold", data.get("seuil_optimal", DEFAULT_THRESHOLD)),
        "decision": data.get("decision", data.get("decision_label", None)),
        "model_name": data.get("model_name", data.get("model", "")),
        "raw_data": data
    }
